在这篇文档中, 我们总结之前实践过的方法, 并汇总成一个合适, 可行的方案.

# 设计原理
现在, 我们先确定一下新项目的基调:

## 目标
在 Python 中以 GNF 范式建模（原子事实、实体锚点、声明式规则），并编译输出为 ProbLog / Datalog 程序：EDB facts + IDB rules。目标引擎只负责求解；identity、cardinality、ER 等语义由 FactPy 在编译阶段保证。理论基础来自于: https://rel.relational.ai/rel/concepts/graph-normal-form#indivisibility-of-facts

## 核心原则

1. Everything is a Relation：标量字段→二元谓词 (Entity, Value)；实体引用字段→二元谓词 (Entity, Entity)。
2. Indivisibility of Facts：原子事实遵循Graph Normal Form, 每个事实最多 1 个 value 列；复杂对象必须 atomize 为原子事实。
3. Things not Strings：连接以 EntityRef 为主；字符串可作为 literal，不可未经 canonicalization 进入 identity。
4. Declarative Logic：规则为 Horn/Datalog 风格子句；变量复用表示 join；可递归（取决于目标方言）。

## 分层

### A) Python Authoring Layer（只表达意图）
* Schema：Entity / Identity / Field（含 cardinality、fact_key）
* Metadata：Meta/docstring（治理元数据）
* Rules：Rule / vars()（Horn clause DSL），Constraint（比较/内建谓词）

### B) Compiler Layer（统一编译管线）
由四个子模块组成，产出目标无关 IR 并保证语义一致：

1. SchemaCompiler：Schema → SchemaIR
	* 收集 entity types、IdentityPolicy、Field 配置（cardinality、fact_key）
	* 生成字段→谓词映射、reification 展开规则、约束配置
	* 可选生成 schema-level facts（供治理/审计）

2. FactCompiler：Instances/Imports → EDB Delta → EDB Store
	* 按 IdentityPolicy 生成 EntityRef（稳定编码、canonical serialization）
	* Atomization：对象粉碎为规范GNF风格谓词事实
	* 依据 SchemaIR 的 cardinality/fact_key 生成 delta（insert/delete/replace）
	* 写入 EDB Store（内存/SQLite/文件快照；replace 语义由 FactCompiler 实现）

3. RuleCompiler：Rule DSL → RuleIR
	* 解析 vars()/Constraint 的 AST
	* 依据 SchemaIR 将 OOP 表达展开为规范二元谓词（含 reification：必要时引入隐变量 E）
	* 类型/域检查：谓词签名、变量域、算术/内建合法性
	* 输出目标无关 Horn IR（RuleIR）

4. Exporter/Runner：EDB Store + RuleIR → Target Program
	* 输出 EDB facts 文件 + IDB rules 文件
	* 方言适配（ProbLog/Soufflé/RDFox…）：内建、比较、聚合、否定、递归限制
	* 可选调用引擎执行并收集派生谓词结果
	* 若方言不支持某 IR 特性：拒绝或降级重写（显式报错，不静默生成）

### C) Target Engine Layer（求解器）
* ProbLog：.pl（facts+rules），支持概率事实与解释
* Datalog（Soufflé/RDFox/DLV 等）：.dl/.dlog（facts+rules）
* 不承担 identity/cardinality/ER 等建模语义，只对输入程序求解

## 关键语义边界（必须写入规范）

1. Identity ≠ fact_key：IdentityPolicy 决定 EntityRef；fact_key/cardinality 决定“同一谓词下事实唯一性与更新语义”。禁止复用 is_key 同时表达两者。
2. Replace 语义由 FactCompiler 负责：目标引擎通常没有“更新”，只有事实集合；functional 属性的“覆盖”必须编译为 delete(old)+insert(new) 或快照重导出。
3. Reification 展开由 SchemaIR 定义：SchemaCompiler 统一命名与展开形态；RuleCompiler/FactCompiler 只按映射生成相同谓词，禁止各自发明谓词名。
4. ER/canonical 必须确定化：若存在 canon_of/merge 等映射，需在上层保证单值或确定 tie-break；不得把多解/不确定映射交给引擎。

## 最小闭环数据流

1. Schema 定义 → SchemaCompiler → SchemaIR
2. 实例化/导入 → FactCompiler → EDB Store（facts 快照/增量）
3. Rule 定义 → RuleCompiler → RuleIR
4. Exporter 输出程序 → 目标引擎求解 → 得到 IDB 派生谓词结果

## 产物清单（MVP）

* SchemaIR：谓词名、字段映射、identity policy、cardinality/fact_key、reification 展开信息
* EDB facts：规范二元事实集合
* RuleIR：目标无关 Horn 子句集合
* Exporters：ProbLog 与至少一个 Datalog 方言（建议 Soufflé）

## （引用）导出与运行规范

* Exporter/Runner 的唯一权威规范见 `/Users/zhenzhili/symbolic_agent/docs/导出与运行.md` 的 `导出与运行（Exporter/Runner）规范（MVP）`。

# 数据层次:
