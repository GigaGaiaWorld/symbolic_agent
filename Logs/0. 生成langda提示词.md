请重构new_problog_agent_parser中面向 LLM 的规则生成 schema/IR，并把数据访问从 CSV 读取中抽象出来。实现必须可测试、可序列化、可扩展到多后端（至少预留 Prolog/ProbLog/Datalog/Cypher 的 renderer 接口）。不要引入递归、聚合、cut。允许否定。系统核心恒定支持概率标注（缺失概率时有默认策略）。

一、核心目标（必须实现）

1. 将规则 schema 拆分为两部分：

* HeadSchema：统一的 head 模板，仅允许变量（var-only）。禁止在 head 中出现任何常量/字面量/列表字面量等。
* Bodies：多个并列的 body，每个 body 对应一个 clause 的 body 部分。语义是“同一 head 的多条规则分支”：Head :- Body_i。body 内 literals 之间默认 AND；不主动引入 disjunction。

2. body 内条件语句（literals）分两类：

* RefLiteral（引用条件语句）：仅引用 FactView 允许的谓词（来自 FactSchema/view），允许否定（negation-as-failure），不允许 cut/聚合/递归。
* ExprLiteral（表达条件语句）：必须是结构化 AST/IR（禁止 raw string）。用于比较、算术、赋值/等式约束、if-then-else、以及“库函数/特殊表达式节点”的调用。

3. FactSchema 与 FactView

* FactSchema 是所有可引用谓词的统一 schema 集合。
* 必须满足 RDF 风格的判同标准：同名 + 同元数 + 同签名 才是同一 schema。签名至少包含参数 datatype（可选 role/namespace）。
* 每个 FactPredicateSchema 必须有稳定唯一 ID（hash），用于引用与去歧义。
* FactView 是从 FactSchema 过滤得到的子集，用于喂给 LLM，RefLiteral 必须只能引用 FactView 中存在的 schema。
* 过滤机制：实现可组合 Filter AST（AND/OR/NOT/PredMatch 等），同时提供 dict filter 作为语法糖（dict -> FilterAST）。

4. DataProvider 抽象（最小可交付）

* 不要求立刻上 DB；但必须把 CSV 数据读取封装为 CSVProvider，并实现 DataProvider 接口。
* view/filter 逻辑不能写死在 CSV 解析里，而应通过 DataProvider 的 query 接口统一实现。

5. 概率（系统核心）

* rules/facts 都可带 probability。
* 缺失概率必须有默认策略（可配置）：default_fact_prob、default_rule_prob、missing_prob_policy（inject_default / warn_and_default / error）。
* 该概率能力是核心实现，不局限于 ProbLog 语法；renderer 按后端映射输出。

二、IR/AST 设计（按此实现，避免后端语义混乱）
实现一个中性 ExprIR（可 JSON 序列化），至少包含：

* Var(name, datatype?)
* Const(value, datatype)
* Call(op, args[])            // 比较/算术/库函数统一表示为 Call
* Unify(lhs, rhs)             // 逻辑等式/赋值约束的统一节点；不要在 IR 里直接写 "=" 或 "is"
* If(cond, then, else)
* Not(expr)                   // 表达式级否定
  并且把 RefLiteral 的否定独立为字段：RefLiteral.negated: bool（用于 not p(X)）。

内建 builtins（最小集合，先落地这些，后续可扩展）

* 比较：eq, ne, lt, le, gt, ge（通过 Call(op, [a,b])）
* 算术：add, sub, mul, div, mod（通过 Call）
* if-then-else：If 节点
* 逻辑等式/绑定：Unify

三、库项（Library）管理（用于适配不同后端语法）
实现一个统一的 Library 机制，管理两类东西的“混合集合”：

* 可引用库谓词（predicate-like，例如 member/2、append/3 或你未来的 domain predicates）
* 特殊表达式节点/函数（expr-node-like）
  统一用 spec 来描述：name、signature、short_doc、typing、backend_mapping 或 backend_impl（可选）。
  renderer 渲染时从 Library 查询 mapping；不要把后端特性散落在业务代码中。


五、Renderer（先做骨架 + 可测试输出）
实现 renderer 接口与最小落地：

* render_rule(rule, backend=...) 输出该 backend 的规则文本（或结构化 code block），至少提供一个 backend（建议 problog 子集）能跑通测试；其他后端先保留接口/占位实现也可，但必须结构清晰。
* 概率渲染：若 rule/fact 缺失概率，按 missing_prob_policy 注入默认值或报错/警告（按配置）。

六、测试与验收（必须通过）
新增/更新测试，至少覆盖：

1. head var-only：含常量 head -> 报错。
2. 多 bodies：同一 head + 两个 bodies -> 渲染为两条 clause。
3. RefLiteral 引用校验：不在 FactView -> 报错。
4. 否定 RefLiteral -> 可渲染。
5. ExprIR(Unify + Compare + If) -> 序列化/反序列化后等价，且 renderer 输出稳定。
6. 概率缺失 -> 采用默认策略（至少覆盖 inject_default）。

同时更新文档（README 或 docs）说明：

* head var-only 原则与“常量赋值在 body 里用 Unify/比较表达”
* clause 语义（多个 bodies = 多条规则分支）
* 否定支持范围与限制（无递归/无聚合/无 cut）
* FactSchema/view 与 filter AST 的使用方式
* DataProvider 扩展点（CSVProvider 已实现，未来可替换 DBProvider）
* 概率默认策略配置项

七、实施要求（Codex 工作方式）

* 先在仓库中定位现有 schema/IR、CSV 读取、规则生成/渲染相关代码；尽量复用现有命名风格与测试框架。
* 改动要模块化：schema/ir、provider、view/filter、renderer、validator、tests 分离。
* 任何新增 public API 都要有类型注解与 docstring。
* 所有错误必须是可诊断的（明确指出是哪条规则/哪个 schema_id/哪个 literal 违反约束）。

开始执行：直接在仓库中实现以上要求，跑通测试，并在最后总结你改动了哪些关键文件与新增了哪些核心类型/接口。